{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/husam6101/Food-Detection-Recognition-and-Ingredient-Allergy-Detection/blob/main/Food_Detection%2C_Regocnition%2C_and_Ingredient_Allergy_Prediction_with_YOLOv5%2C_ResNet%2C_and_XGBoost_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Food Detection, Regocnition, and Ingredient-Allergy Prediction with YOLOv5, ResNet, and XGBoost Fine-Tuning**\n",
        "**Project by:** Husam Shamseddine and Roy Zoghbi"
      ],
      "metadata": {
        "id": "r0iJEL6nTeEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akzg9umP2wBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06813241-610b-4e75-ea13-e1b4f000ad31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBifN-jzHGKT"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "# TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, LSTM, Embedding\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Other ML and data processing libraries\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Other libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Args Definition and Initialization**"
      ],
      "metadata": {
        "id": "83r7l16NW1lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Defining Args Class**\n",
        "# @markdown For easier control over hyperparameters and training settings\n",
        "# @markdown ## **Parameters**\n",
        "# @markdown - `resnet_batch_size`: Batch size for the ResNet model\n",
        "# @markdown - `resnet_learning_rate`: Learning rate for the resnet model\n",
        "# @markdown - `resnet_epochs`: Number of epochs for the resnet model\n",
        "# @markdown - `resnet_split`: Validation:Training split for the resnet model\n",
        "# @markdown - `resnet_number_of_classes`: Number of classes that ResNet is being trained on,\n",
        "# @markdown calculated automatically from the dataset\n",
        "# @markdown - `resnet_model_path`: Save file path for ResNet\n",
        "# @markdown - `yolov5_path`: Save file path for YOLOv5\n",
        "# @markdown - `xgboost_batch_size`: Batch size for the XGBoost Model\n",
        "# @markdown - `xgboost_learning_rate`: Learning rate for the XGBoost model\n",
        "# @markdown - `xgboost_n_estimators`: Number of estimators for the XGBoost model\n",
        "# @markdown - `xgboost_max_depth`: Mad depth parameter for the XGBoost model\n",
        "# @markdown - `xgboost_split`: Validation:Training split for the XGBoost model\n",
        "# @markdown - `xgboost_random_state`: Random state parameter for the data going into the XGBoost model\n",
        "# @markdown - `xgboost_model_location`; Save file path for XGBoost\n",
        "\n",
        "\n",
        "class Args:\n",
        "  def __init__(\n",
        "      self,\n",
        "      resnet_batch_size,\n",
        "      resnet_learning_rate,\n",
        "      resnet_epochs,\n",
        "      resnet_split,\n",
        "      resnet_model_path,\n",
        "      yolov5_path,\n",
        "      xgboost_n_estimators,\n",
        "      xgboost_learning_rate,\n",
        "      xgboost_max_depth,\n",
        "      xgboost_split,\n",
        "      xgboost_random_state,\n",
        "      xgboost_model_path\n",
        "  ):\n",
        "    self.resnet_batch_size = resnet_batch_size\n",
        "    self.resnet_learning_rate = resnet_learning_rate\n",
        "    self.resnet_epochs = resnet_epochs\n",
        "    self.resnet_split = resnet_split\n",
        "    self.resnet_model_path = resnet_model_path\n",
        "    self.yolov5_path = yolov5_path\n",
        "    self.xgboost_n_estimators = xgboost_n_estimators\n",
        "    self.xgboost_learning_rate = xgboost_learning_rate\n",
        "    self.xgboost_max_depth = xgboost_max_depth\n",
        "    self.xgboost_split = xgboost_split\n",
        "    self.xgboost_random_state = xgboost_random_state\n",
        "    self.xgboost_model_path = xgboost_model_path\n",
        "\n",
        "    self.resnet_number_of_classes = None"
      ],
      "metadata": {
        "id": "IgdoGohQVD0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Initializing Default Args**\n",
        "# @markdown ## **ResNet For Object Recognition**\n",
        "resnet_batch_size = 32 # @param {type:\"integer\"}\n",
        "resnet_learning_rate = 0.0002 # @param {type:\"number\"}\n",
        "resnet_epochs = 20 # @param {type:\"integer\"}\n",
        "resnet_split = 0.2 # @param {type:\"number\"}\n",
        "resnet_model_path = \"/content/drive/MyDrive/project/final/ResNet_best.h5\" # @param {type:\"string\"}\n",
        "# @markdown ## **YOLOv5 for Food Object Detection**\n",
        "yolov5_path = \"/content/drive/MyDrive/project/final/\" # @param {type:\"string\"}\n",
        "# @markdown ## **XGBoost for Ingredient and Allergy Prediction**\n",
        "xgboost_n_estimators = 100 # @param {type:\"integer\"}\n",
        "xgboost_learning_rate = 0.05 # @param {type:\"number\"}\n",
        "xgboost_max_depth = 4 # @param {type:\"integer\"}\n",
        "xgboost_split = 0.2 # @param {type:\"number\"}\n",
        "xgboost_random_state = 42 # @param {type:\"integer\"}\n",
        "xgboost_model_path = \"/content/drive/MyDrive/project/final/XGBoost_best.h5\" # @param {type:\"string\"}\n",
        "\n",
        "args = Args(\n",
        "    resnet_batch_size = resnet_batch_size,\n",
        "    resnet_learning_rate = resnet_learning_rate,\n",
        "    resnet_epochs = resnet_epochs,\n",
        "    resnet_split = resnet_split,\n",
        "    resnet_model_path = resnet_model_path,\n",
        "    yolov5_path = yolov5_path,\n",
        "    xgboost_n_estimators = xgboost_n_estimators,\n",
        "    xgboost_learning_rate = xgboost_learning_rate,\n",
        "    xgboost_max_depth = xgboost_max_depth,\n",
        "    xgboost_split = xgboost_split,\n",
        "    xgboost_random_state = xgboost_random_state,\n",
        "    xgboost_model_path = xgboost_model_path,\n",
        ")\n",
        "\n",
        "# deleting variables to avoid propagating them global beyond this cell\n",
        "del resnet_batch_size\n",
        "del resnet_learning_rate\n",
        "del resnet_epochs\n",
        "del resnet_split\n",
        "del resnet_model_path\n",
        "del yolov5_path\n",
        "del xgboost_n_estimators\n",
        "del xgboost_learning_rate\n",
        "del xgboost_max_depth\n",
        "del xgboost_split\n",
        "del xgboost_random_state\n",
        "del xgboost_model_path"
      ],
      "metadata": {
        "id": "Wsu-SDD5VaF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **YOLOv5**"
      ],
      "metadata": {
        "id": "DIjj6k1SvCCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cloning and Pre-Treating Data**"
      ],
      "metadata": {
        "id": "sbMXN_QOwYja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## **Get Food Detection Data for YOLOv5**\n",
        "%cd /content/\n",
        "!gdown https://drive.google.com/uc?id=1vKfBWxTTu2Bcvu-MofBw4GMDsPK8AukH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud99IZxyk2GH",
        "outputId": "9eb8d0ae-5e57-42f1-ce01-45da634580e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vKfBWxTTu2Bcvu-MofBw4GMDsPK8AukH\n",
            "To: /content/OID.zip\n",
            "100% 976M/976M [00:14<00:00, 68.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## **Extract the Data from the .zip File**\n",
        "%cd /content/\n",
        "!unzip -o \"/content/OID.zip\" -d '/content/OID'"
      ],
      "metadata": {
        "id": "kRnjRX_ZmiQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Treating Issues with OID Data**\n",
        "# @markdown The downloaded and extracted OID data is missing its data.yaml file,\n",
        "# @markdown therefore it would required to modify all label .txt files to set their class to `0`,\n",
        "# @markdown and create a data.yaml file for the `food` class for detection\n",
        "# @markdown ## **Process**\n",
        "# @markdown 1. **Modify text files for `train_coco` and `val_coco`:** Loop through all text files and set the first part of every line,\n",
        "# @markdown   that refers to the class to `0`\n",
        "# @markdown 2. **Change directory names:** of `train_coco`` and `val_coco` to `train` and `valid`\n",
        "def modify_text_files(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):  # Check if it's a text file\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r') as file:\n",
        "                lines = file.readlines()\n",
        "\n",
        "            with open(file_path, 'w') as file:\n",
        "                for line in lines:\n",
        "                    if line.strip():  # Check if the line is not empty\n",
        "                        file.write('0 ' + line[1:])\n",
        "                    else:\n",
        "                        file.write(line)\n",
        "\n",
        "def change_folder_name(old_name, new_name):\n",
        "    try:\n",
        "        os.rename(old_name, new_name)\n",
        "        print(f\"Folder renamed from {old_name} to {new_name}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error: {e.strerror}\")\n",
        "\n",
        "modify_text_files('/content/OID/OID/labels/train_coco/')\n",
        "modify_text_files('/content/OID/OID/labels/val_coco/')\n",
        "change_folder_name('/content/OID/OID/labels/train_coco/', '/content/OID/OID/labels/train/')\n",
        "change_folder_name('/content/OID/OID/labels/val_coco/', '/content/OID/OID/labels/valid/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln-r18bko08j",
        "outputId": "fa00125d-76ff-4430-c138-1011d817bb1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder renamed from /content/OID/OID/labels/train_coco/ to /content/OID/OID/labels/train/\n",
            "Folder renamed from /content/OID/OID/labels/val_coco/ to /content/OID/OID/labels/valid/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Create data.yaml**\n",
        "# @markdown Create a data.yaml file and fill it as follows:\n",
        "# @markdown > train: /content/OID/OID/images/train<br>\n",
        "# @markdown > val: /content/OID/OID/images/valid<br><br>\n",
        "# @markdown > nc: 1<br>\n",
        "# @markdown > names: ['food']\n",
        "print('Creating data.yaml...')\n",
        "with open('/content/OID/OID/data.yaml', 'w') as config_file:\n",
        "    config_file.write(\"train: /content/OID/OID/images/train\\n\")\n",
        "    config_file.write(\"val: /content/OID/OID/images/valid\\n\\n\")\n",
        "    config_file.write(\"nc: 1\\n\")\n",
        "    config_file.write(\"names: ['food']\\n\")\n",
        "\n",
        "print('Finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUuY2GdMq89q",
        "outputId": "804fcc82-9aaa-456b-d60a-0aa893061861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating data.yaml...\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cloning, Training, and Testing of YOLOv5**"
      ],
      "metadata": {
        "id": "V-xYRAaPz4DF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sh5zhOXDILB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9176cbe7-cf30-4863-b912-9171240c2c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project/final\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16094, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 16094 (delta 0), reused 4 (delta 0), pack-reused 16089\u001b[K\n",
            "Receiving objects: 100% (16094/16094), 14.76 MiB | 14.12 MiB/s, done.\n",
            "Resolving deltas: 100% (11024/11024), done.\n",
            "/content/drive/MyDrive/project/final/yolov5\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Collecting Pillow>=10.0.1 (from -r requirements.txt (line 9))\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
            "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.227-py3-none-any.whl (660 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, Pillow, gitdb, thop, gitpython, ultralytics\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.227\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ## **Clone YOLOv5 and Install Requirements**\n",
        "# @markdown > Note: Often times does Colab requires a restart of the runtime\n",
        "# @markdown after installing the requirements,\n",
        "# @markdown and rerunning past cells becomes necessary for volatile imports, and definitions\n",
        "%cd {args.yolov5_path}\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/project/final/yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9Tgd77pA_Wi",
        "outputId": "9693ca0e-8333-4054-f0d0-e8150f0c00c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project/final/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.40)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
            "Requirement already satisfied: ultralytics>=8.0.147 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.0.227)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swSzVBGDDJmO"
      },
      "outputs": [],
      "source": [
        "# @markdown # **Train Yolov5**\n",
        "# @markdown Train yolo on the previously treated OID data for food detection\n",
        "# @markdown > Note: Some warnings may appear due to corrupt image data,\n",
        "# @markdown > but the remaining, uncorrupted data is still more than enough to get a good result\n",
        "%cd {args.yolov5_path + '/yolov5'}\n",
        "!python train.py --img 640 --batch 16 --epochs 10 --data '/content/OID/OID/data.yaml' --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwjCl2jSDLBy"
      },
      "outputs": [],
      "source": [
        "# @title **Test YOLOv5**\n",
        "# @markdown # **Test YOLOv5**\n",
        "# @markdown Test yolo on an image\n",
        "# @markdown > Test cells is currently commented for the sake of a smoother-running process\n",
        "# %cd {args.yolov5_path + yolov5}\n",
        "# !python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source \"/content/apple-pie.png\" --save-txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ResNet50**"
      ],
      "metadata": {
        "id": "pjgBg6zQUweS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kaggle Setup**"
      ],
      "metadata": {
        "id": "um99w7LlTV_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Setup kaggle.json**\n",
        "# @markdown > Upload **Kaggle.json** in */content/* then run\n",
        "import os\n",
        "\n",
        "# Create a Kaggle folder\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Move the kaggle.json file\n",
        "%cd /content/\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "# Set permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wztgVXXmAmwi",
        "outputId": "9bfca5ae-8c03-498a-aeca-6184e46ba27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Download Data from Kaggle**\n",
        "# @markdown Download and unzip the **food101tiny** from Kaggle in <u>*/content*</u>\n",
        "%cd /content/\n",
        "!kaggle datasets download -d msarmi9/food101tiny -p /content/\n",
        "# unzipping contents of .zip dataset\n",
        "!unzip \"/content/food101tiny.zip\" -d '/content/food101tiny'"
      ],
      "metadata": {
        "id": "G1OmhnkXZLuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b114af3a-a239-4c19-e418-70208ad300a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "food101tiny.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/food101tiny.zip\n",
            "replace /content/food101tiny/data/food-101-tiny/train/apple_pie/1005649.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ResNet Setup and Preprocessing**"
      ],
      "metadata": {
        "id": "Y0nY9Feohn-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Loading Data from Directories + Augmentation**\n",
        "# @markdown ## **Dataset Directory Parameters**\n",
        "train_dir = '/content/food101tiny/data/food-101-tiny/train' # @param {type: \"string\"}\n",
        "test_dir = '/content/food101tiny/data/food-101-tiny/valid' # @param {type: \"string\"}\n",
        "\n",
        "# @markdown ## **Data Augmentation Parameters**\n",
        "rotation_range = 20 #@param {type: \"integer\"}\n",
        "width_shift_range = 0.2 #@param (type: \"number\")\n",
        "height_shift_range = 0.2 #@param {type: \"number\"}\n",
        "shear_range = 0.2 #@param {type: \"number\"}\n",
        "zoom_range = 0.2 #@param {type: \"number\"}\n",
        "horizontal_flip = True #@param {type: \"boolean\"}\n",
        "\n",
        "# @markdown ## **Process**\n",
        "# @markdown Load data and perform data augmentation using `ImageDataGenerator`\n",
        "# @markdown as well as split the data through to `train_generator` and `validation_generator`\n",
        "# @markdown where the `target_size` is appropriately set to `(224,224)` for ResNet fine-tuning\n",
        "\n",
        "# Define the data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range = rotation_range,\n",
        "    width_shift_range = width_shift_range,\n",
        "    height_shift_range = height_shift_range,\n",
        "    shear_range = shear_range,\n",
        "    zoom_range = zoom_range,\n",
        "    horizontal_flip = horizontal_flip,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = args.resnet_split\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (224, 224),\n",
        "    batch_size = args.resnet_batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (224, 224),\n",
        "    batch_size = args.resnet_batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")\n",
        "\n",
        "del train_dir\n",
        "del test_dir\n",
        "del rotation_range\n",
        "del width_shift_range\n",
        "del height_shift_range\n",
        "del shear_range\n",
        "del zoom_range\n",
        "del horizontal_flip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWUYlXNtDG_G",
        "outputId": "d8962ca4-87f4-4509-f54d-81840f23963e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 images belonging to 10 classes.\n",
            "Found 100 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Getting Class Number and Treating Labels**\n",
        "# @markdown ## **Process**\n",
        "# @markdown First, extract the number of classes as well as `class_labels` from `train_generator` (`validation_generator` would work too)\n",
        "# @markdown then replace the underscores in `class_labels` with a space\n",
        "\n",
        "args.resnet_number_of_classes = len(train_generator.class_indices)\n",
        "\n",
        "# Getting class labels\n",
        "class_indices = train_generator.class_indices\n",
        "class_labels = [label.replace('_', ' ') for label in class_indices.keys()]\n",
        "class_labels.sort(key=lambda label: class_indices[label.replace(' ', '_')])\n",
        "\n",
        "print(f'Number of classes: {args.resnet_number_of_classes}')\n",
        "print(f'Labels: {class_labels}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-31r8lyWdIru",
        "outputId": "4c27019e-8431-4469-fc73-563d3a3ade9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n",
            "Labels: ['apple pie', 'bibimbap', 'cannoli', 'edamame', 'falafel', 'french toast', 'ice cream', 'ramen', 'sushi', 'tiramisu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training and Testing Fine-Tuned ResNet Model**"
      ],
      "metadata": {
        "id": "TCkN4UNqrdAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njWjlSh0Heui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedd4f17-487d-4d56-ff30-46437969bc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, None, None, 3)        0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, None, None, 64)       9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, None, None, 64)       256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, None, None, 64)       0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, None, None, 64)       0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, None, None, 64)       0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, None, None, 64)       4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, None, None, 256)      16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, None, None, 256)      0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, None, None, 256)      0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, None, None, 256)      0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, None, None, 256)      0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, None, None, 256)      0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, None, None, 256)      0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, None, None, 128)      32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, None, None, 512)      131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, None, None, 512)      0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, None, None, 512)      0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, None, None, 512)      0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, None, None, 512)      0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, None, None, 512)      0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, None, None, 512)      0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, None, None, 512)      0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, None, None, 512)      0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, None, None, 256)      131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, None, None, 1024)     525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, None, None, 1024)     0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, None, None, 1024)     0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, None, None, 1024)     0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, None, None, 1024)     0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, None, None, 1024)     0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, None, None, 1024)     0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, None, None, 1024)     0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, None, None, 1024)     0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, None, None, 1024)     0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, None, None, 1024)     0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, None, None, 512)      524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, None, None, 2048)     2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, None, None, 2048)     0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, None, None, 2048)     0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, None, None, 2048)     0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, None, None, 2048)     0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1024)                 2098176   ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 10)                   10250     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25696138 (98.02 MB)\n",
            "Trainable params: 2108426 (8.04 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# @title Fine-Tune the Layers\n",
        "# @markdown # **Finetune ResNet Layers**\n",
        "# @markdown ## **Process**\n",
        "# @markdown 1. Load the ResNet50 model pre-trained on ImageNet data\n",
        "# @markdown 2. Freeze the layers in the base model\n",
        "# @markdown 3. Add the layers:\n",
        "# @markdown   1. `GlobalAveragePooling2D` to the top layer\n",
        "# @markdown   2. A fully connected `Dense` layer with `ReLU` activation\n",
        "# @markdown   3. A logistic `Dense` layer for the previously extracted `args.resnet_number_of_classes`\n",
        "# @markdown     that will serve as an output\n",
        "# @markdown 4. Compile the model\n",
        "# @markdown\n",
        "# @markdown\n",
        "# @markdown > Note: The model uses `categorical_crossentropy` as a loss function\n",
        "# @markdown and keeps track of `accuracy` in its metrics\n",
        "\n",
        "base_model = ResNet50(weights = 'imagenet', include_top = False)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation = 'relu')(x)\n",
        "predictions = Dense(args.resnet_number_of_classes, activation = 'softmax')(x)\n",
        "\n",
        "model = Model(inputs = base_model.input, outputs = predictions)\n",
        "model.summary()\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate = args.resnet_learning_rate),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boLgyEYJHi4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40f924b-fe5f-4332-af70-d4a302eb34f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4430 - accuracy: 0.5058\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/38 [==============================] - 36s 608ms/step - loss: 1.4430 - accuracy: 0.5058 - val_loss: 0.8989 - val_accuracy: 0.7100\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.7825\n",
            "Epoch 2: val_accuracy improved from 0.71000 to 0.75000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n",
            "38/38 [==============================] - 23s 613ms/step - loss: 0.6803 - accuracy: 0.7825 - val_loss: 0.7396 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8350\n",
            "Epoch 3: val_accuracy improved from 0.75000 to 0.77000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n",
            "38/38 [==============================] - 27s 726ms/step - loss: 0.5109 - accuracy: 0.8350 - val_loss: 0.6851 - val_accuracy: 0.7700\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.8533\n",
            "Epoch 4: val_accuracy did not improve from 0.77000\n",
            "38/38 [==============================] - 22s 574ms/step - loss: 0.4356 - accuracy: 0.8533 - val_loss: 0.7144 - val_accuracy: 0.7400\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8925\n",
            "Epoch 5: val_accuracy did not improve from 0.77000\n",
            "38/38 [==============================] - 22s 584ms/step - loss: 0.3582 - accuracy: 0.8925 - val_loss: 0.6599 - val_accuracy: 0.7600\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.9125\n",
            "Epoch 6: val_accuracy improved from 0.77000 to 0.79000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n",
            "38/38 [==============================] - 23s 608ms/step - loss: 0.2894 - accuracy: 0.9125 - val_loss: 0.6428 - val_accuracy: 0.7900\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9233\n",
            "Epoch 7: val_accuracy improved from 0.79000 to 0.81000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n",
            "38/38 [==============================] - 26s 686ms/step - loss: 0.2426 - accuracy: 0.9233 - val_loss: 0.5508 - val_accuracy: 0.8100\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9383\n",
            "Epoch 8: val_accuracy did not improve from 0.81000\n",
            "38/38 [==============================] - 21s 548ms/step - loss: 0.2098 - accuracy: 0.9383 - val_loss: 0.5951 - val_accuracy: 0.7900\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9483\n",
            "Epoch 9: val_accuracy did not improve from 0.81000\n",
            "38/38 [==============================] - 21s 546ms/step - loss: 0.1803 - accuracy: 0.9483 - val_loss: 0.6511 - val_accuracy: 0.7900\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9600\n",
            "Epoch 10: val_accuracy did not improve from 0.81000\n",
            "38/38 [==============================] - 21s 547ms/step - loss: 0.1560 - accuracy: 0.9600 - val_loss: 0.7091 - val_accuracy: 0.7800\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9600\n",
            "Epoch 11: val_accuracy improved from 0.81000 to 0.82000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n",
            "38/38 [==============================] - 22s 593ms/step - loss: 0.1491 - accuracy: 0.9600 - val_loss: 0.6615 - val_accuracy: 0.8200\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9783\n",
            "Epoch 12: val_accuracy did not improve from 0.82000\n",
            "38/38 [==============================] - 23s 597ms/step - loss: 0.1150 - accuracy: 0.9783 - val_loss: 0.6291 - val_accuracy: 0.7700\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9692\n",
            "Epoch 13: val_accuracy did not improve from 0.82000\n",
            "38/38 [==============================] - 25s 644ms/step - loss: 0.1180 - accuracy: 0.9692 - val_loss: 0.6043 - val_accuracy: 0.7600\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9842\n",
            "Epoch 14: val_accuracy did not improve from 0.82000\n",
            "38/38 [==============================] - 21s 543ms/step - loss: 0.0934 - accuracy: 0.9842 - val_loss: 0.6302 - val_accuracy: 0.7900\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9808\n",
            "Epoch 15: val_accuracy improved from 0.82000 to 0.83000, saving model to /content/drive/MyDrive/project/final/ResNet_best.h5\n",
            "38/38 [==============================] - 24s 612ms/step - loss: 0.0855 - accuracy: 0.9808 - val_loss: 0.5813 - val_accuracy: 0.8300\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9850\n",
            "Epoch 16: val_accuracy did not improve from 0.83000\n",
            "38/38 [==============================] - 25s 668ms/step - loss: 0.0773 - accuracy: 0.9850 - val_loss: 0.8629 - val_accuracy: 0.7600\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9800\n",
            "Epoch 17: val_accuracy did not improve from 0.83000\n",
            "38/38 [==============================] - 22s 561ms/step - loss: 0.0870 - accuracy: 0.9800 - val_loss: 0.5125 - val_accuracy: 0.8300\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9892\n",
            "Epoch 18: val_accuracy did not improve from 0.83000\n",
            "38/38 [==============================] - 21s 547ms/step - loss: 0.0641 - accuracy: 0.9892 - val_loss: 0.8072 - val_accuracy: 0.7100\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9800\n",
            "Epoch 19: val_accuracy did not improve from 0.83000\n",
            "38/38 [==============================] - 22s 571ms/step - loss: 0.0806 - accuracy: 0.9800 - val_loss: 0.6664 - val_accuracy: 0.8000\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9892\n",
            "Epoch 20: val_accuracy did not improve from 0.83000\n",
            "38/38 [==============================] - 23s 586ms/step - loss: 0.0596 - accuracy: 0.9892 - val_loss: 0.5737 - val_accuracy: 0.8200\n"
          ]
        }
      ],
      "source": [
        "# @title Train the Model\n",
        "# @markdown ## **Training the model**\n",
        "checkpoint_path = args.resnet_model_path\n",
        "# @markdown ## **Process**\n",
        "\n",
        "# @markdown 1. Implementing checkpointing for best model with `ModelCheckpoint`\n",
        "# @markdown   > Note that the checkpoint monitors `val_accuracy` in `max` mode\n",
        "# @markdown     and that `save_best_only` is set to `True`\n",
        "# @markdown\n",
        "# @markdown\n",
        "# @markdown 2. Calculate the values of `steps_per_epoch` and `validation_steps` based on (samples / batch_size)\n",
        "# @markdown 3. Train the model\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "steps_per_epoch = math.ceil(train_generator.samples / train_generator.batch_size)\n",
        "validation_steps = math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=args.resnet_epochs,\n",
        "    callbacks = [checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_03RUw42HmZX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Test the Model\n",
        "# @markdown > Test cells are currently commented for the sake of a smoother-running process\n",
        "# @markdown # **Load the Model and Test it Against an Image**\n",
        "# @markdown ## **Parameters**\n",
        "img_path = '/content/apple-pie.png' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ## **Process**\n",
        "# @markdown 1. Load the model\n",
        "# @markdown 2. Load the image and resize it\n",
        "# @markdown 3. Process the image into an `img_array`\n",
        "# @markdown 4. Predict using the loaded model\n",
        "# @markdown 5. Get the index of the top prediction\n",
        "# @markdown 6. Get the top prediction's labela dn probability\n",
        "# @markdown 7. Display results\n",
        "\n",
        "# loaded_model = load_model(args.resnet_model_path)\n",
        "\n",
        "# img = Image.load_img(img_path, target_size=(224, 224))\n",
        "# img_array = Image.img_to_array(img)\n",
        "# img_array = np.expand_dims(img_array, axis=0)\n",
        "# img_array = preprocess_input(img_array)\n",
        "\n",
        "# predictions = loaded_model.predict(img_array)\n",
        "\n",
        "# # Get the index of the top prediction\n",
        "# top_index = predictions[0].argmax()\n",
        "\n",
        "# # Get the top prediction label and probability\n",
        "# top_prediction_label = class_labels[top_index]\n",
        "# top_prediction_probability = predictions[0][top_index]\n",
        "\n",
        "# print(\"Top Prediction:\", top_prediction_label)\n",
        "# print(\"Probability:\", top_prediction_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGBoost**"
      ],
      "metadata": {
        "id": "6aGXvLRG2K-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the Dataset and Preprocessing It**"
      ],
      "metadata": {
        "id": "vnO1WidwcXsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Downloaded the dataset .csv from drive**\n",
        "%cd /content/\n",
        "!gdown https://drive.google.com/uc?id=1yxoxiYNQW-tylsdBX-nrqSZbzfd_nZoV"
      ],
      "metadata": {
        "id": "UnMt8rEQ3iUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2cbd81-69a0-4c8e-c32d-e8fd33480950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yxoxiYNQW-tylsdBX-nrqSZbzfd_nZoV\n",
            "To: /content/food-to-allergies-optimized-dataset.csv\n",
            "100% 201k/201k [00:00<00:00, 65.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Load the Dataset and Preprocess it for XGBoost's Fine-Tuning**\n",
        "# @markdown ## **Process**\n",
        "# @markdown 1. Load the dataset\n",
        "# @markdown 2. Check for missing values and handle them if found\n",
        "# @markdown 3. Encode the `DISH` and `Allergy` columns separately\n",
        "# @markdown 4. Define the features (`DISH`) and target (`Allergy`)\n",
        "# @markdown 5. Split the dataset\n",
        "\n",
        "df = pd.read_csv('/content/food-to-allergies-optimized-dataset.csv') # 1\n",
        "df.dropna(inplace=True)  # 2. removes rows with missing values\n",
        "\n",
        "# 3\n",
        "dish_label_encoder = LabelEncoder()\n",
        "df['DISH'] = dish_label_encoder.fit_transform(df['DISH'].astype(str))\n",
        "allergy_label_encoder = LabelEncoder()\n",
        "df['Allergy'] = allergy_label_encoder.fit_transform(df['Allergy'].astype(str))\n",
        "\n",
        "# 4\n",
        "X = df[['DISH']]\n",
        "y = df['Allergy']\n",
        "\n",
        "# 5\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=args.xgboost_split,\n",
        "    random_state=args.xgboost_random_state\n",
        ")"
      ],
      "metadata": {
        "id": "CLbPT-DzEigA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train, Evaluate, and Setup XGBoost for Implementation with YOLOv5 and ResNet50**"
      ],
      "metadata": {
        "id": "fPZxHOhGcl47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Train and Evaluate XGBoost**\n",
        "# Train the XGBoost model\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=args.xgboost_n_estimators,\n",
        "    learning_rate=args.xgboost_learning_rate,\n",
        "    max_depth=args.xgboost_max_depth\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.save_model(args.xgboost_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CahMp3CEsbo",
        "outputId": "712f5963-cb65-4599-ee04-ac9f943a785e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 22.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [15:23:21] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Extract Ingredients and Allergies, and Construct a Sentence**\n",
        "# @markdown By decoding the encoded result from the prediction with the corresponding decoder\n",
        "# @markdown ## **Process**\n",
        "# @markdown 1. `get_ingredients_and_allergies`\n",
        "# @markdown   1. The first function takes in `dish_encoded`\n",
        "# @markdown   and filters through the ddataframe to find the dish\n",
        "# @markdown   2. It then gets the dish `ingredients` and `allergies` associated with it\n",
        "# @markdown 2. construct_sentence: Takes in the data and builds the sentence from it\n",
        "def get_ingredients_and_allergies(dish_encoded, df):\n",
        "    dish_data = df[df['DISH'] == dish_encoded]\n",
        "    ingredients = dish_data['Food'].tolist()\n",
        "    allergies = dish_data['Allergy'].tolist()\n",
        "    return ingredients, allergies\n",
        "\n",
        "def construct_sentence(dish_encoded, df, dish_name, allergy_label_encoder):\n",
        "    ingredients, allergy_codes = get_ingredients_and_allergies(dish_encoded, df)\n",
        "    if not ingredients or not allergy_codes:\n",
        "        return f\"No allergy information available for {dish_name}.\"\n",
        "\n",
        "    allergy_names = allergy_label_encoder.inverse_transform(allergy_codes)\n",
        "    parts = [f\"{ingredient} (which may cause {allergy})\" for ingredient, allergy in zip(ingredients, allergy_names)]\n",
        "    sentence = f\"{dish_name.title()} contains \" + ', '.join(parts) + '.'\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "LO2z9zF39mbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Integration of YOLOv5, ResNet50, and XGBoost**"
      ],
      "metadata": {
        "id": "wi20FG_jcyIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **YOLOv5 and ResNet50 Automatic Run Funtions**\n",
        "# @markdown **Short summary of the functions in this cell:**<br>\n",
        "# @markdown `get_latest_exp_folder` Fetches the latest exp folder that contains the latest YOLOv5 result<br>\n",
        "# @markdown `run_tolo_and_parse_results` is pretty self explanatory<br>\n",
        "# @markdown `crop_image` cropped the original image to the bbox provided by YoOLOv5<br>\n",
        "# @markdown `load_and_preprocess_for_resnet` also self explanatory<br>\n",
        "# @markdown `predict_with_resnet` makes use of the fine-tuned resnet model to recognize which foods got detected by the YOLOv5 model\n",
        "\n",
        "def get_latest_exp_folder(base_path):\n",
        "    exp_folders = glob.glob(os.path.join(base_path, 'exp*'))\n",
        "    if exp_folders:\n",
        "        latest_folder = max(exp_folders, key=os.path.getmtime)\n",
        "        print(latest_folder)\n",
        "        return latest_folder\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def run_yolo_and_parse_results(image_path, weights_path, confidence=0.25):\n",
        "    print('Running YOLOv5 script')\n",
        "\n",
        "    yolo_command = f\"python {args.yolov5_path}yolov5/detect.py --weights {weights_path} --img 640 --conf {confidence} --source {image_path} --save-txt\"\n",
        "    print(yolo_command)\n",
        "    # result = subprocess.run(yolo_command.split(), shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    # os.system(yolo_command)\n",
        "    with subprocess.Popen(yolo_command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE) as proc:\n",
        "      stdout, stderr = proc.communicate()\n",
        "      print(\"Output:\", stdout.decode())\n",
        "      print(\"Error:\", stderr.decode())\n",
        "    print('Fetching detected result')\n",
        "    yolo_base_dir = f'{args.yolov5_path}yolov5/runs/detect'\n",
        "    latest_exp_dir = get_latest_exp_folder(yolo_base_dir)\n",
        "\n",
        "    print('Treating output')\n",
        "    if latest_exp_dir:\n",
        "        yolo_output_file = os.path.join(latest_exp_dir, 'labels', os.path.basename(image_path).replace('.png', '.txt'))\n",
        "        detections = []\n",
        "        if os.path.exists(yolo_output_file):\n",
        "            with open(yolo_output_file, 'r') as file:\n",
        "                for line in file:\n",
        "                    detections.append(line.strip().split())\n",
        "        return detections\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def crop_image(image_path, bbox):\n",
        "    with Image.open(image_path) as img:\n",
        "        cropped_img = img.crop((bbox[0], bbox[1], bbox[2], bbox[3]))  # left, top, right, bottom\n",
        "        return cropped_img\n",
        "\n",
        "def load_and_preprocess_for_resnet(img):\n",
        "    print('Preprocessing image for ResNet')\n",
        "    # If img is a path, load the image\n",
        "    if isinstance(img, str):\n",
        "        img = keras_image.load_img(img, target_size=(224, 224))\n",
        "\n",
        "    # If img is a PIL Image, resize it\n",
        "    elif isinstance(img, Image.Image):\n",
        "        img = img.resize((224, 224))\n",
        "\n",
        "    img_array = keras_image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "\n",
        "# Function to predict with ResNet\n",
        "def predict_with_resnet(model_path, img_array):\n",
        "  print('Feeding through ResNet')\n",
        "  # Load ResNet model\n",
        "  loaded_model = load_model(model_path)\n",
        "  predictions = loaded_model.predict(img_array)\n",
        "\n",
        "  # Get the top prediction\n",
        "  top_index = predictions[0].argmax()\n",
        "  top_prediction_label = class_labels[top_index]  # class_labels must be defined previously\n",
        "  top_prediction_probability = predictions[0][top_index]\n",
        "\n",
        "  return top_prediction_label, top_prediction_probability"
      ],
      "metadata": {
        "id": "We_zZmeeEyy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # **Run the Process From Start To Finish**\n",
        "# @markdown YOLOv5 > ResNet50 > XGBoost > Final Result\n",
        "# @markdown ## **Parameters**\n",
        "image_test = '/content/drive/MyDrive/project/final/apple-pie.png' # @param {type:\"string\"}\n",
        "yolo_weights = '/content/drive/MyDrive/project/final/yolov5/runs/train/exp/weights/best.pt' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ## **Process**\n",
        "# @markdown 1. Run YOLOv5 and save its `detections`\n",
        "# @markdown 2. Loops through `detections` and saves their coordinates adjusts them to the image dimensions\n",
        "# @markdown 3. Cropps the image, preprocesses it, and runs it into the ResNet50 model\n",
        "# @markdown 4. After the label is output from the ResNet50 model, it gets encoded and runs through XGBoost\n",
        "# @markdown 5. XGBoost then outputs the ingredients and their associated allergies,\n",
        "# @markdown   which then get processed and output in a easy-to-understand format\n",
        "\n",
        "# Updated usage of YOLO and ResNet\n",
        "detections = run_yolo_and_parse_results(image_test, yolo_weights)\n",
        "\n",
        "for detection in detections:\n",
        "    # Convert bbox coordinates from YOLO format\n",
        "    # Assuming bbox is [class, x_center, y_center, width, height]\n",
        "    x_center, y_center, width, height = map(float, detection[1:5])\n",
        "    image_width, image_height = Image.open(image_test).size\n",
        "    left = int((x_center - width / 2) * image_width)\n",
        "    top = int((y_center - height / 2) * image_height)\n",
        "    right = int((x_center + width / 2) * image_width)\n",
        "    bottom = int((y_center + height / 2) * image_height)\n",
        "    bbox = [left, top, right, bottom]\n",
        "\n",
        "    cropped_img = crop_image(image_test, bbox)\n",
        "    img_array = load_and_preprocess_for_resnet(cropped_img)\n",
        "    label, probability = predict_with_resnet(args.resnet_model_path, img_array)\n",
        "    print(\"Top Prediction:\", label)\n",
        "    print(\"Probability:\", probability)\n",
        "\n",
        "    new_dish = label\n",
        "    try:\n",
        "      # Load the XGBoost model\n",
        "      xgboost_model = xgb.XGBClassifier()\n",
        "      xgboost_model.load_model(args.xgboost_model_path)  # Ensure this is the correct path to your model file\n",
        "\n",
        "      new_dish_encoded = dish_label_encoder.transform([new_dish.lower()])[0]\n",
        "      predicted_allergy = xgboost_model.predict([[new_dish_encoded]])[0]\n",
        "      detailed_info = construct_sentence(new_dish_encoded, df, new_dish, allergy_label_encoder)\n",
        "      print(detailed_info)\n",
        "    except ValueError as e:\n",
        "        # Handle the case where the dish is not in the dataset\n",
        "        print(f\"The dish '{label}' is not available in the dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id0nP8-HFpnA",
        "outputId": "9cd45bea-fc63-4e7d-8be9-52df21eabda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running YOLOv5 script\n",
            "python /content/drive/MyDrive/project/final/yolov5/detect.py --weights /content/drive/MyDrive/project/final/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/project/final/apple-pie.png --save-txt\n",
            "Output: \n",
            "Error: \u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/project/final/yolov5/runs/train/exp/weights/best.pt'], source=/content/drive/MyDrive/project/final/apple-pie.png, data=drive/MyDrive/project/final/yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/project/final/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-249-gf400bba Python-3.10.12 torch-2.1.0+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/drive/MyDrive/project/final/apple-pie.png: 640x640 3 foods, 412.2ms\n",
            "Speed: 2.1ms pre-process, 412.2ms inference, 6.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mdrive/MyDrive/project/final/yolov5/runs/detect/exp2\u001b[0m\n",
            "1 labels saved to drive/MyDrive/project/final/yolov5/runs/detect/exp2/labels\n",
            "\n",
            "Fetching detected result\n",
            "/content/drive/MyDrive/project/final/yolov5/runs/detect/exp2\n",
            "Treating output\n",
            "Preprocessing image for ResNet\n",
            "Feeding through ResNet\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Top Prediction: edamame\n",
            "Probability: 0.7486906\n",
            "The dish 'edamame' is not available in the dataset.\n",
            "Preprocessing image for ResNet\n",
            "Feeding through ResNet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e0d0fc06c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Top Prediction: apple pie\n",
            "Probability: 0.90357524\n",
            "Apple Pie contains Butter (which may cause Milk allergy / Lactose intolerance), Butter bean (which may cause Legume Allergy), Buttermilk (which may cause Milk allergy / Lactose intolerance), Sugar (which may cause Sugar Allergy / Intolerance), Sugar beet (which may cause Sugar Allergy / Intolerance), Sugarcane (which may cause Sugar Allergy / Intolerance), Apple (which may cause Oral Allergy Syndrome), Pineapple (which may cause Oral Allergy Syndrome), Chestnut (which may cause Nut Allergy), Ginkgo nut (which may cause Nut Allergy), Peanut (which may cause Peanut Allergy), Walnut (which may cause Nut Allergy).\n",
            "Preprocessing image for ResNet\n",
            "Feeding through ResNet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e0d12e81870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Top Prediction: ice cream\n",
            "Probability: 0.520703\n",
            "Ice Cream contains Buttermilk (which may cause Milk allergy / Lactose intolerance), Milk (which may cause Milk allergy / Lactose intolerance).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}